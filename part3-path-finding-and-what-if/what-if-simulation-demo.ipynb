{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Route Finding What-If Scenarios\n",
    "Effect of high Centrality Airport Delays on Freight-Forwarding Performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "\n",
    "# Use Neo4j URI and credentials according to your setup\n",
    "gds = GraphDataScience('neo4j://localhost', auth=('neo4j', 'neo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get all Historic Routes and Calculate shortest Paths Based on Historic Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clear_all_graphs():\n",
    "    g_names = gds.graph.list().graphName.tolist()\n",
    "    for g_name in g_names:\n",
    "        g = gds.graph.get(g_name)\n",
    "        gds.graph.drop(g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NODE_PROJ_QUERY = '''\n",
    "        MATCH(n)\n",
    "        WHERE n:EntryPoint OR n:DepartureWarehouse OR n:DeparturePoint OR n:ArrivalWarehouse OR n:TransferPoint OR n:Destination\n",
    "        RETURN id(n) as id, labels(n) as labels\n",
    "        '''\n",
    "REL_PROJ_QUERY = '''\n",
    "        MATCH(n0)-[r:RECEPTION|DEPARTURE|TRANSPORT|DELIVERY]->(n1)\n",
    "        RETURN id(n0) AS source, id(n1) AS target, type(r) AS type, avg(r.effectiveMinutes) AS averageEffectiveMinutes\n",
    "        '''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clear_all_graphs()\n",
    "g, _ = gds.graph.project.cypher('proj', NODE_PROJ_QUERY, REL_PROJ_QUERY)\n",
    "_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get all shipments\n",
    "route_df = gds.run_cypher('''\n",
    "    MATCH (n:EntryPoint)-[r:RECEPTION]->()\n",
    "    WITH r.shipmentId AS shipmentId, id(n) AS sourceNodeId, n.airportId AS sourceAirportId\n",
    "    MATCH (n:Destination)<-[r:DELIVERY {shipmentId : shipmentId}]-()\n",
    "    WHERE n.airportId <> sourceAirportId\n",
    "    RETURN sourceNodeId, id(n) AS targetNodeId, sourceAirportId, n.airportId AS targetAirportId, collect(shipmentId) AS shipmentIds, count(*) AS shipmentCount\n",
    "    ORDER BY shipmentCount DESC\n",
    "''')\n",
    "route_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_airport_ids(path_df):\n",
    "    res = set()\n",
    "    for ind, row in path_df.iterrows():\n",
    "        res.update([i.get('airportId') for i in row.path.nodes])\n",
    "    return res\n",
    "\n",
    "def get_best_path_airport_ids(path_df):\n",
    "    res = set()\n",
    "    for ind, row in path_df[path_df.totalCost == path_df.totalCost.min()].iterrows():\n",
    "        res.update([i.get('airportId') for i in row.path.nodes])\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "path_dfs={}\n",
    "for ind, row in route_df.iterrows():\n",
    "    path_df = gds.shortestPath.yens.stream(g, sourceNode=row.sourceNodeId, targetNode=row.targetNodeId,\n",
    "                                           k=20, relationshipWeightProperty='averageEffectiveMinutes')\n",
    "    path_dfs[(row.sourceAirportId, row.targetAirportId)] = path_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Recommended Fright Forwarding Solutions for Historic Shipments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shipment_df = route_df.explode('shipmentIds').groupby(['shipmentIds', 'targetNodeId', 'targetAirportId'])\\\n",
    "    .agg({'sourceNodeId':list, 'sourceAirportId':list, }).reset_index()\n",
    "shipment_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_solution(row, path_dfs, multiplier_airport_id=None, multiplier=3.0):\n",
    "    solution = row.solutionIndex\n",
    "    rels = {}\n",
    "    path_costs = []\n",
    "    airport_ids = set()\n",
    "    for n in range(len(solution)):\n",
    "        path_costs.append(path_dfs[n].totalCost[solution[n]])\n",
    "        for r in path_dfs[n].path[solution[n]].relationships:\n",
    "            rels[f'{r.start_node.id}-{r.end_node.id}'] = r\n",
    "            m=1.0\n",
    "            airport_id = r.end_node.get('airportId')\n",
    "            airport_ids.add(airport_id)\n",
    "            if (multiplier_airport_id is not None) and (airport_id == multiplier_airport_id):\n",
    "                m = multiplier\n",
    "    return sum([r.get('cost')*m for r in rels.values()]), path_costs, list(rels.values()), airport_ids\n",
    "\n",
    "\n",
    "def best_k_solutions(path_df_dict, source_airport_ids, target_airport_id, top_k=10, multiplier_airport_id=None, multiplier=3.0):\n",
    "    path_df_list = []\n",
    "    for source_airport_id in source_airport_ids:\n",
    "        path_df_list.append(path_df_dict[(source_airport_id, target_airport_id)].copy())\n",
    "\n",
    "    solution_df = pd.DataFrame(itertools.product(*[range(path_df.shape[0]) for path_df in path_df_list]))\\\n",
    "        .apply(tuple, axis=1).to_frame(name='solutionIndex')\n",
    "    solution_df[['totalCost','pathCosts', 'relationships', 'airportIds']] = solution_df.apply(get_solution,\n",
    "                                                                                args=(path_df_list, multiplier_airport_id, multiplier), axis=1, result_type='expand')\n",
    "    return solution_df.sort_values('totalCost')[:top_k].reset_index(drop=True)\n",
    "\n",
    "def best_solution(path_df_dict, source_airport_ids, target_airport_id, multiplier_airport_id=None, multiplier=3.0):\n",
    "    res = best_k_solutions(path_df_dict, source_airport_ids, target_airport_id, top_k=1,\n",
    "                           multiplier_airport_id=multiplier_airport_id, multiplier=multiplier)\n",
    "    return res.loc[0,'totalCost'], res.loc[0,'airportIds']\n",
    "\n",
    "def baseline_solution(row, path_df_dict):\n",
    "    return best_solution(path_df_dict, row.sourceAirportId, row.targetAirportId)\n",
    "\n",
    "def top_solution(row, path_df_dict, multiplier_airport_id, multiplier=3.0):\n",
    "    if multiplier_airport_id not in row.baselineAirportIds:\n",
    "        return row.baselineCost\n",
    "    return best_solution(path_df_dict, row.sourceAirportId, row.targetAirportId, multiplier_airport_id, multiplier)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Taking a sub-sample will cut down on computation time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shipment_df_sample = shipment_df.sample(n=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "shipment_df_sample[['baselineCost', 'baselineAirportIds']] = \\\n",
    "    shipment_df_sample.apply(baseline_solution, axis=1, args=[path_dfs], result_type='expand')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shipment_df_sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What-If Scenarios\n",
    "For each airport that was used as a transfer point, simulate a 3x delay in processing time and re-calculate best freight forwarding combinations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "airport_ids = gds.run_cypher('''\n",
    "    MATCH (n:TransferPoint)-[r:RECEPTION]->()\n",
    "    RETURN DISTINCT n.airportId as airportId\n",
    "''')['airportId'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "cnt = 0\n",
    "for airport_id in airport_ids:\n",
    "    shipment_df_sample[ f'cost_{airport_id}_delay'] = shipment_df_sample.apply(top_solution, axis=1,\n",
    "                                             args=(path_dfs, airport_id, 3.0), result_type='expand')\n",
    "    cnt+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shipment_df_sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregate Total Delay Time and Number of Delays Then Compare to Centrality Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_baseline = sum(shipment_df_sample['baselineCost'])\n",
    "total_delays = []\n",
    "for airport_id in airport_ids:\n",
    "    total_delays.append({'airportId': airport_id,\n",
    "                         'totalTimePercIncrease': (sum(shipment_df_sample[f'cost_{airport_id}_delay']) - total_baseline)/total_baseline,\n",
    "                         'totalTimeIncrease': sum(shipment_df_sample[f'cost_{airport_id}_delay']) - total_baseline,\n",
    "                         'numberOfDelayedShipments': sum(shipment_df_sample[f'cost_{airport_id}_delay'] > shipment_df_sample['baselineCost']),\n",
    "                         'maxDelayTime': max(shipment_df_sample['cost_140_delay'] - shipment_df_sample['baselineCost'])})\n",
    "total_delay_df = pd.DataFrame(total_delays)\n",
    "total_delay_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gds.run_cypher('''\n",
    "    MATCH(a1:Airport)<-[:LOCATED_AT]-(d1:DeparturePoint)-[r:TRANSPORT]->(d2:ArrivalWarehouse)-[:LOCATED_AT]->(a2:Airport)\n",
    "    WITH a1, a2, count(r) AS flightCount\n",
    "    MERGE (a1)-[s:SENDS_TO]->(a2)\n",
    "    SET s.flightCount = flightCount\n",
    "    RETURN count(s)\n",
    "''')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g.drop()\n",
    "# Create the in-memory graph projection\n",
    "g, _ = gds.graph.project('proj', 'Airport', {'SENDS_TO': {'properties': ['flightCount']}})\n",
    "# calculate and write out-degree centrality\n",
    "gds.degree.write(g, relationshipWeightProperty='flightCount', writeProperty='outDegreeCentrality')\n",
    "# calculate and write betweenness centrality\n",
    "gds.betweenness.write(g, writeProperty='betweennessCentrality')\n",
    "#calculate and write eigenvector centrality\n",
    "gds.eigenvector.write(g, relationshipWeightProperty='flightCount', writeProperty='eigenvectorCentrality')\n",
    "# drop the projected in-memory graph\n",
    "g.drop()\n",
    "## Calculate In-Degree Centrality on REVERSED Orientation\n",
    "g, _ = gds.graph.project('proj', 'Airport', {'SENDS_TO': {'orientation': 'REVERSE', 'properties': ['flightCount']}})\n",
    "gds.degree.write(g, relationshipWeightProperty='flightCount', writeProperty='inDegreeCentrality')\n",
    "g.drop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "airport_df = gds.run_cypher('''\n",
    "    MATCH(a:Airport)\n",
    "    RETURN a.airportId as airportId,\n",
    "        a.name AS name,\n",
    "        a.inDegreeCentrality AS inDegreeCentrality,\n",
    "        a.outDegreeCentrality AS outDegreeCentrality,\n",
    "        a.betweennessCentrality AS betweennessCentrality,\n",
    "        a.eigenvectorCentrality AS eigenvectorCentrality\n",
    "''')\n",
    "airport_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = total_delay_df.merge(airport_df, on='airportId')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[['totalTimeIncrease', 'totalTimePercIncrease', 'numberOfDelayedShipments', 'maxDelayTime',\n",
    "    'betweennessCentrality', 'eigenvectorCentrality', 'inDegreeCentrality', 'outDegreeCentrality']].corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.sort_values('numberOfDelayedShipments', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}